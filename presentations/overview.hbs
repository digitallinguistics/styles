<main id=home>

  <!-- establish the audience and the types of data they have -->
  <section>
    <ol>
      <li>You’re a linguist.</li>
      <li>You have data.</li>
      <li>A <span class=smallcaps>lot</span> of data.</li>
      <li>Data of all sorts.</li>
      <li>Audio recordings.</li>
      <li>Time-aligned transcripts.</li>
      <li>Interlinear glosses.</li>
      <li>Metadata.</li>
      <li>More audio recordings.</li>
      <li>Video recordings.</li>
      <li>Audio recordings to accompany the video recordings.</li>
      <li>Scans of notebooks.</li>
      <li>Old manuscripts.</li>
      <li>File slips.</li>
      <li>Word lists in spreadsheets.</li>
    </ol>
  </section>

  <!-- the problem: fracturation of data -->
  <section>
    <ol>
      <li>All this is great!</li>
      <li>Then you start to annotate your data.</li>
      <li>You start an ELAN file, and create a time-aligned transcript.</li>
      <li>Now you want a lexicon. So you start a FLEx database and put your texts into it.</li>
      <li>But hmm... It looks like past tense is marked by high tone. You need to double-check your recordings.</li>
      <li>Back to ELAN to check those tones...</li>
      <li>You want to look at causatives next, but now you’d have to search through all that stuff.</li>
      <li>There’s no unified search. You can’t track words or grammatical categories across your various forms of documentation.</li>
      <li>All this jumping between different tools isn’t just slow and inefficient, it’s error-prone and makes it difficult to keep your data in sync.</li>
      <li>Every time you start a different task, you fracture your data.</li>
      <li>One more thing to keep in sync with everything else. The more work you do, the harder your maintenance becomes.</li>
    </ol>
  </section>

  <!-- the DLX solution -->
  <section>
    <ol>
      <li>Aren’t computers supposed to help us with these things?</li>
      <li>Wouldn’t it be great if you could focus on what you do best – linguistic analysis – rather than wrangling data from one application to another?</li>
      <li>We think so too.</li>
      <li><strong>Digital Linguistics (DLX)</strong> is designed to address this problem.</li>
      <li>Digital Linguistics uses web technologies to represent the data structures you already know in a way that is readable by computers.</li>
      <li>We want you to be able to use a common data format for all your different tasks.</li>
      <li>That data format is designed to mimic the way you already think about your data — as a hierarchy of texts, phrases, words, morphemes, and phonemes.</li>
      <!-- picture of an interlinear text -->
      <li>You already understand the data model that this notation encodes.</li>
      <li>You recognize these structures visually and conceptually, but computers don’t have eyes.</li>
      <li>What Digital Linguistics does is to simply model that knowledge for the computer.</li>
      <!-- picture of JSON -->
      <li>Here’s that same data structure, in a format computers (and humans!) can read.</li>
    </ol>
  </section>

  <!-- types of annotations -->
  <section>
    <ol>
      <li>This data format (known as JSON), is how most data is exchanged on the web today.</li>
      <li>This simple format can capture a huge variety of data types.</li>
      <li>Start and end times for phrases.</li>
      <li>Speaker labels.</li>
      <li>Code-switched portions of text, and their language.</li>
      <li>Time-aligned indexes and annotations.</li><!-- example of a sociocultural index -->
      <li>Or even open-ended tags.</li><!-- example of a grammatical role tag -->
      <li>Geographic coordinates.</li>
      <li>Multiple representations of the same data.</li><!-- two different orthographies -->
      <li>The granular and hierarchical representation of your data used by DLX allows you to explore new avenues of research and collaboration, whatever your documentary priorities.</li>
    </ol>
  </section>

  <!-- portability, extensibility -->
  <section>
    <ol>
      <li>Once your data is in this format, any annotations you add will be accessible from any other other web-based tool.</li>
      <li>Separate linguistic tasks become commensurable and avoid multiplying effort with every new annotation task.</li>
      <li>Since these web-based tools run in a web browser (e.g. Chrome, Edge, Firefox), you can run them from any computer.</li>
      <li>The web platform liberates the process, the linguist, and the research team from inter-platform incompatabilities.</li>
      <li>No more importing, exporting, reformatting, and keeping data in sync.</li>
      <li>No more of being chained to one piece of software, or one operating system.</li>
      <li>One format, many tools.</li>
      <li><span class=smallcaps>Complete data freedom.</span></li>
    </ol>
  </section>

  <!-- tools and tasks that DLX makes possible -->
  <section>
    <ol>
      <li>And since the DLX format is the data format of the web, it can take advantage of the robust suite of tools available in web browsers and online.</li>
      <li>Like concordance searching with playable audio.</li>
      <li>Or the ability to search <span class=smallcaps>all</span> your data, from any computer.</li>
      <li>And to collect and visualize statistical and frequency data about your corpus or particular constructions.</li>
      <li>Create online storybooks with playable audio for language revitalization.</li>
      <li>Even things like pitch extraction and digital signal processing.</li><!-- show a pitch trace in a browser -->
      <li>Even better, you don’t even have to be online for these features to work — they’re built into every web browser.</li>
      <li>And web browsers are constantly adding new features, which will enable new tools we haven’t even imagined yet.</li>
      <li>The tools you use to work with your data can always avail themselves of the latest the web has to offer.</li>
    </ol>
  </section>

  <!-- conclusion -->
  <section>
    <ol>
      <li>Digital Linguistics is devoted to understanding the best practices for the digital representation, manipulation, storage, and dissemination of documentary linguistic data.</li>
      <li>Put simply, we want to make documentary linguistics digital.</li>
      <li>To use the linguistic structures you already know, but in a form you can use.</li>
      <li>To significantly reduce the time cost of data input and management.</li>
      <li>And to enable linguists to do what they do best: linguistics.</li>
    </ol>
  </section>

</main>
